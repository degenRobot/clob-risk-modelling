{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLOB Risk Model - Executive Summary\n",
    "\n",
    "## Professional Risk Analysis Dashboard\n",
    "\n",
    "This notebook provides a comprehensive risk analysis for perpetual CLOBs, combining CEX and AMM liquidity metrics with advanced visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from risk_model import (\n",
    "    config, binance_data, uniswap_data, \n",
    "    pricing, plotting, metrics, scenarios,\n",
    "    volume_analysis\n",
    ")\n",
    "\n",
    "# Professional styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Risk Analysis Framework v0.1.0\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Market Overview & Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and fetch market data\n",
    "markets_config = config.load_markets()\n",
    "risk_params = config.get_risk_parameters()\n",
    "\n",
    "# Initialize data fetchers\n",
    "binance = binance_data.BinanceDataFetcher()\n",
    "\n",
    "# Fetch data for all configured markets\n",
    "market_data = {}\n",
    "print(\"Fetching market data...\\n\")\n",
    "\n",
    "for market in markets_config['markets'][:3]:  # Top 3 markets\n",
    "    symbol = market['binance_symbol_perp']\n",
    "    print(f\"ðŸ“Š {market['name']} ({symbol})\")\n",
    "    \n",
    "    try:\n",
    "        # Fetch all data\n",
    "        orderbook = binance.get_orderbook(symbol, limit=500)\n",
    "        ticker = binance.get_ticker_24h(symbol)\n",
    "        klines = binance.get_klines(symbol, interval='1h', lookback_days=30)\n",
    "        \n",
    "        # Process liquidity\n",
    "        liq_curve = pricing.compute_orderbook_liquidity_curve(orderbook)\n",
    "        cex_depth = pricing.depth_at_impact(liq_curve, risk_params['max_price_impact_pct'])\n",
    "        \n",
    "        # Calculate volatility\n",
    "        vol = pricing.realized_vol(klines)\n",
    "        \n",
    "        # Volume analysis\n",
    "        vol_analysis, vol_profile = volume_analysis.analyze_volume_patterns(klines)\n",
    "        \n",
    "        market_data[market['name']] = {\n",
    "            'symbol': symbol,\n",
    "            'orderbook': orderbook,\n",
    "            'liquidity_curve': liq_curve,\n",
    "            'ticker': ticker,\n",
    "            'klines': klines,\n",
    "            'volume_analysis': vol_analysis,\n",
    "            'current_price': klines['close'].iloc[-1],\n",
    "            'volume_24h_usd': float(ticker['quoteVolume']),\n",
    "            'cex_liquidity_usd': cex_depth,\n",
    "            'total_liquidity_usd': cex_depth,  # CEX only for now\n",
    "            'realized_vol': vol,\n",
    "            'asset': market['name'].split('-')[0],\n",
    "            'oracle_meta': {'type': market['oracle']}\n",
    "        }\n",
    "        print(f\"  âœ“ Price: ${market_data[market['name']]['current_price']:,.2f}\")\n",
    "        print(f\"  âœ“ 24h Volume: ${market_data[market['name']]['volume_24h_usd']:,.0f}\")\n",
    "        print(f\"  âœ“ Liquidity @ 1%: ${market_data[market['name']]['cex_liquidity_usd']:,.0f}\")\n",
    "        print(f\"  âœ“ Volatility: {market_data[market['name']]['realized_vol']*100:.1f}%\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {e}\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Professional Visualizations\n",
    "\n",
    "### 2.1 Market Depth Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create professional depth visualization\n",
    "if market_data:\n",
    "    first_market = list(market_data.keys())[0]\n",
    "    liq_curve = market_data[first_market]['liquidity_curve']\n",
    "    \n",
    "    fig, axes = plotting.plot_orderbook_depth(liq_curve, title=f\"{first_market} Order Book Depth\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Risk Score Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate risk scores for all markets\n",
    "risk_scores = []\n",
    "market_names = []\n",
    "\n",
    "for name, data in market_data.items():\n",
    "    # Calculate all metrics\n",
    "    all_metrics = metrics.calculate_all_metrics(data)\n",
    "    \n",
    "    scores = all_metrics['scores']\n",
    "    risk_scores.append([\n",
    "        scores['liquidity'],\n",
    "        scores['volatility'],\n",
    "        scores['oracle'],\n",
    "        scores['composite']\n",
    "    ])\n",
    "    market_names.append(name)\n",
    "\n",
    "# Create risk matrix DataFrame\n",
    "risk_matrix = pd.DataFrame(\n",
    "    risk_scores, \n",
    "    index=market_names,\n",
    "    columns=['Liquidity', 'Volatility', 'Oracle', 'Composite']\n",
    ")\n",
    "\n",
    "# Plot professional heatmap\n",
    "fig, ax = plotting.plot_risk_heatmap(risk_matrix, \"Risk Assessment Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRisk Score Summary:\")\n",
    "print(risk_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Volatility Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare volatility data for multiple assets\n",
    "vol_data = {}\n",
    "\n",
    "for name, data in market_data.items():\n",
    "    klines = data['klines']\n",
    "    \n",
    "    # Calculate rolling volatility\n",
    "    returns = np.log(klines['close'] / klines['close'].shift(1)).dropna()\n",
    "    rolling_vol = returns.rolling(window=24*7).std() * np.sqrt(365 * 24)\n",
    "    \n",
    "    vol_df = pd.DataFrame(index=klines.index)\n",
    "    vol_df['volatility'] = rolling_vol\n",
    "    \n",
    "    # Add confidence bands (simplified)\n",
    "    vol_df['vol_lower'] = vol_df['volatility'] * 0.8\n",
    "    vol_df['vol_upper'] = vol_df['volatility'] * 1.2\n",
    "    \n",
    "    vol_data[name] = vol_df.dropna()\n",
    "\n",
    "# Plot volatility surface\n",
    "fig, ax = plotting.plot_volatility_surface(vol_data, \"Volatility Dynamics Across Markets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Volume-Depth Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze volume-depth relationship for first market\n",
    "if market_data:\n",
    "    first_market = list(market_data.keys())[0]\n",
    "    data = market_data[first_market]\n",
    "    \n",
    "    # Prepare volume and depth time series\n",
    "    vol_analysis = data['volume_analysis']\n",
    "    \n",
    "    # Create depth time series (simulated for demonstration)\n",
    "    depth_df = pd.DataFrame(index=vol_analysis.index)\n",
    "    depth_df['depth_1pct'] = data['cex_liquidity_usd'] * (1 + 0.1 * np.random.randn(len(depth_df)))\n",
    "    depth_df['depth_2pct'] = depth_df['depth_1pct'] * 1.5\n",
    "    \n",
    "    volume_data = {\n",
    "        'volume': vol_analysis[['volume']],\n",
    "        'depth': depth_df\n",
    "    }\n",
    "    \n",
    "    fig, axes = plotting.plot_volume_depth_correlation(volume_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Limits & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate OI limits table\n",
    "limits_data = []\n",
    "\n",
    "for name, data in market_data.items():\n",
    "    all_metrics = metrics.calculate_all_metrics(data)\n",
    "    \n",
    "    limits_data.append({\n",
    "        'Market': name,\n",
    "        'Risk Score': all_metrics['scores']['composite'],\n",
    "        'Total Liquidity': data['total_liquidity_usd'],\n",
    "        'Max OI': all_metrics['limits']['max_oi_usd'],\n",
    "        'Max Position': all_metrics['limits']['max_position_usd'],\n",
    "        'OI/Volume Ratio': all_metrics['health']['oi_to_volume_ratio'],\n",
    "        'Health Status': all_metrics['health']['oi_health_status']\n",
    "    })\n",
    "\n",
    "limits_df = pd.DataFrame(limits_data)\n",
    "\n",
    "# Display formatted table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED POSITION LIMITS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Format for display\n",
    "display_df = limits_df.copy()\n",
    "for col in ['Total Liquidity', 'Max OI', 'Max Position']:\n",
    "    display_df[col] = display_df[col].apply(lambda x: f'${x/1e6:.1f}M')\n",
    "display_df['OI/Volume Ratio'] = display_df['OI/Volume Ratio'].apply(lambda x: f'{x:.2f}x')\n",
    "\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# Create visual table\n",
    "fig, ax = plotting.plot_oi_limits_table(display_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stress Testing Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run stress scenarios for the first market\n",
    "if market_data:\n",
    "    first_market = list(market_data.keys())[0]\n",
    "    data = market_data[first_market]\n",
    "    \n",
    "    # Get recommended max OI\n",
    "    all_metrics = metrics.calculate_all_metrics(data)\n",
    "    max_oi = all_metrics['limits']['max_oi_usd']\n",
    "    \n",
    "    # Run scenarios\n",
    "    stress_scenarios = scenarios.run_all_scenarios(data, max_oi)\n",
    "    \n",
    "    # Summarize results\n",
    "    scenario_df = scenarios.summarize_scenarios(stress_scenarios)\n",
    "    \n",
    "    # Plot scenario impacts\n",
    "    fig, ax = plotting.plot_scenario_impacts(scenario_df)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nStress Test Summary:\")\n",
    "    print(scenario_df[['scenario', 'severity', 'impact_pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Volume Analysis & Market Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate volume analysis reports\n",
    "volume_reports = []\n",
    "\n",
    "for name, data in market_data.items():\n",
    "    # Calculate liquidity scores\n",
    "    book_ticker = binance.get_book_ticker(data['symbol'])\n",
    "    spread_metrics = pricing.calculate_spread_metrics(book_ticker)\n",
    "    \n",
    "    liq_score = volume_analysis.calculate_liquidity_score(\n",
    "        data['volume_24h_usd'],\n",
    "        data['cex_liquidity_usd'],\n",
    "        spread_metrics['spread_bps']\n",
    "    )\n",
    "    \n",
    "    # Analyze volume-volatility relationship\n",
    "    vol_vol_analysis = volume_analysis.analyze_volume_volatility_relationship(\n",
    "        data['volume_analysis'],\n",
    "        data['realized_vol']\n",
    "    )\n",
    "    \n",
    "    volume_reports.append({\n",
    "        'Market': name,\n",
    "        'Liquidity Score': f\"{liq_score['composite_liquidity_score']:.3f}\",\n",
    "        'Liquidity Rating': liq_score['liquidity_rating'],\n",
    "        'Volume Consistency': f\"{vol_vol_analysis['volume_consistency']:.3f}\",\n",
    "        'High Volume Days': f\"{vol_vol_analysis['pct_high_volume_days']:.1f}%\",\n",
    "        'Vol/Activity Ratio': f\"{vol_vol_analysis['vol_activity_ratio']:.2f}\"\n",
    "    })\n",
    "\n",
    "volume_df = pd.DataFrame(volume_reports)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MARKET QUALITY ASSESSMENT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(volume_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. P&L Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate P&L scenarios based on historical data\n",
    "pnl_scenarios = pd.DataFrame()\n",
    "\n",
    "for name, data in market_data.items():\n",
    "    klines = data['klines']\n",
    "    returns = klines['close'].pct_change().dropna() * 100  # Percentage returns\n",
    "    \n",
    "    # Simulate leveraged P&L (5x leverage)\n",
    "    leverage = 5\n",
    "    pnl_scenarios[f'{name}_5x'] = returns * leverage\n",
    "\n",
    "# Plot P&L distribution\n",
    "if not pnl_scenarios.empty:\n",
    "    fig, axes = plotting.plot_pnl_distribution(pnl_scenarios, \"Leveraged P&L Distribution Analysis\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    print(\"\\nRisk Metrics (5x Leverage):\")\n",
    "    for col in pnl_scenarios.columns:\n",
    "        var_95 = np.percentile(pnl_scenarios[col].dropna(), 5)\n",
    "        cvar_95 = pnl_scenarios[col][pnl_scenarios[col] <= var_95].mean()\n",
    "        max_dd = (pnl_scenarios[col].cumsum()).min()\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  VaR 95%: {var_95:.2f}%\")\n",
    "        print(f\"  CVaR 95%: {cvar_95:.2f}%\")\n",
    "        print(f\"  Max Drawdown: {max_dd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary & Recommendations\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Based on the comprehensive analysis above, here are the key risk management recommendations:\n",
    "\n",
    "1. **Position Limits**: Implement the recommended OI limits based on available liquidity and risk scores\n",
    "2. **Risk Monitoring**: Markets with composite risk scores > 3 require enhanced monitoring\n",
    "3. **Stress Testing**: Regular stress tests should be conducted, especially for cascade scenarios\n",
    "4. **Liquidity Management**: Maintain OI/Volume ratios below 5x for healthy market functioning\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Implement real-time monitoring of these metrics\n",
    "2. Set up alerts for risk threshold breaches\n",
    "3. Integrate AMM liquidity data when available\n",
    "4. Conduct regular parameter recalibration based on market conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis timestamp\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Framework Version: 0.1.0\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLOB Risk",
   "language": "python",
   "name": "clob-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}